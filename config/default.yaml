dataset:
    root: "data/"
    batch_size: 64
model:
    model_embedding_size: 64
    model_attention_heads: 3
    model_layers: 4
    model_dropout_rate: 0.2
    model_top_k_ratio: 0.5
    model_top_k_every_n: 1
    model_dense_neurons: 256
optimizer:
    name: "adam"
    lr: 0.001
    weight_decay: 0.00001
    momentum: NA
training:
    loss_fn: "bce"
    max_epochs: 100
    early_stop_count: 5
    gpu_node: "0"
